{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 8: Linear Regression\n",
    "\n",
    "\n",
    "In this exercise, you will apply linear regression and Lasso regression methods to the dataset supplied to you, and then compare their results to determine whether Lasso regression is needed for this dataset:\n",
    "\n",
    "**Dataset description**: You are provided a dataset with 20 variables. Variables $x1\\ -\\ x19$ refer to the independent variables, while variable $y$ is your dependent variable. Training data is stored in the file `/etc/data/regression-train.csv`.\n",
    "\n",
    "**Note**: The TA will use a test set to verify your solution. The format (independent variables $x1\\ -\\ x19$, dependent variable  $y$) will be same, but TA's file may contain different number of data points than the split version from training set. Please ensure you take this into account, and do not hard code any dimensions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09b96daf1e0cf44e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb0404ec9da83a2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Read the data\n",
    "df = pd.read_csv(\"./data/regression-train.csv\")\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eef1468ef64e4e98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression, it is particularly important to normalize our data before\n",
    "# training the model, so we can better interpret our coefficients\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_unscaled)\n",
    "X_train = scaler.transform(X_train_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have given you a function to caculate the RMSE of a regression model, given its predictions and the ground truth y-values of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d1c351adc22eb14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "  \n",
    "  # Inputs:\n",
    "  # y_true: ground truth dependent variable values, of type vector\n",
    "  # y_pred: prediction outcomes from any regression method, with the same length as y_true\n",
    "  \n",
    "  # Outputs:\n",
    "  # a single value of type double, with the RMSE value\n",
    "    return(math.sqrt(np.sum((y_true - y_pred)**2)/len(y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Regression (Group)\n",
    "You will write code in the function `alda_regression_linear` to train simple linear regression. Detailed instructions for implementation and allowed packages have been provided the comments.\n",
    "\n",
    "Before your begin, read the documentation on sklearn's [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_regression_linear",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def alda_regression_linear(X_train, X_test, y_train):\n",
    "    # Perform linear regression\n",
    "    # Inputs:\n",
    "    # X_train: training data frame(19 variables, x1-x19)\n",
    "    # X_test: test data frame(19 variables, x1-x19)\n",
    "    # y_train: dependent variable, training data (vector, continous type)\n",
    "\n",
    "    # Output:\n",
    "    # A tuple containing:\n",
    "    # - The regression model and \n",
    "    # - The list of predictions on test data (X_test) (vector) \n",
    "  \n",
    "    # allowed packages: sklearn.linear_model\n",
    "  \n",
    "    # Function hints: Read the documentation for the functions LinearRegression (link above)\n",
    "    \n",
    "    # write code for building a linear regression model using X_train, y_train\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test your model\n",
    "lr_model, lr_predictions = alda_regression_linear(X_train, X_test, y_train)\n",
    "\n",
    "print(f'Training RMSE: {calculate_rmse(y_train, lr_model.predict(X_train))}')\n",
    "print(f'Test RMSE: {calculate_rmse(y_test, lr_predictions)}')\n",
    "print('')\n",
    "\n",
    "# Which attributes are most predictive of the outcome variable?\n",
    "print(f'Model coefficients:\\n{lr_model.coef_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_linear-public",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_model, simple_linear_regression_result = alda_regression_linear(X_train, X_test, y_train)\n",
    "np.testing.assert_equal(simple_linear_regression_result.shape, (27,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test,simple_linear_regression_result),787.9099436300563)\n",
    "np.testing.assert_almost_equal(lr_model.coef_[0], 48.18082989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_linear-private",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here's some test cases to make sure you're right\n",
    "df_test = pd.read_csv(\"./data/regression-test.csv\")\n",
    "X_test2 = df_test.iloc[:,:-1]\n",
    "y_test2 = df_test.iloc[:,-1]\n",
    "\n",
    "lr_model, simple_linear_regression_result = alda_regression_linear(X, X_test2, y)\n",
    "np.testing.assert_equal(simple_linear_regression_result.shape, (66,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test2,simple_linear_regression_result),946.4318403560575)\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Lasso Regression (Group)\n",
    "You will write code in the function `alda_regression_lasso` to train simple lasso regression. Detailed instructions for implementation and allowed packages have been provided the comments. \n",
    "\n",
    "Before your begin, read the documentation on sklearn's [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) - a Lasso regression model that uses CV to tune its hyperparameters.\n",
    "\n",
    "**Note** that the lasso regression model has *built-in* crossvalidation, which it performs on the training dataset provided, to select the best shrinkage coefficient for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_regression_lasso",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "def alda_regression_lasso(X_train, X_test, y_train, random_state=0):\n",
    "    # Perform lasso regression\n",
    "    # Inputs:\n",
    "    # X_train: training data frame(19 variables, x1-x19)\n",
    "    # X_test: test data frame(19 variables, x1-x19)\n",
    "    # y_train: dependent variable, training data (vector, continous type)\n",
    "    # random_state: a random state to use in CV model training\n",
    "    # General Information:\n",
    "        # use 10-fold cross validation to determine the best model hyperparameters\n",
    "    \n",
    "    # Output:\n",
    "    # A tuple containing:\n",
    "    # - The regression model and \n",
    "    # - The list of predictions on test data (X_test) (vector) \n",
    "  \n",
    "    # allowed packages: sklearn.linear_model\n",
    "  \n",
    "    # Function hints: Read the documentation for the functions LassoCV (link above)\n",
    "    \n",
    "    # write code for lasso regression here\n",
    "    # 10 fold cross validation\n",
    "    # set up the random_state as 0 in order for reproducibility\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before testing your model**: Do you expect the training error to be higher or lower? What about the testing error? What do you expect to be different about the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model, lasso_predictions = alda_regression_lasso(X_train, X_test, y_train)\n",
    "\n",
    "# Should be ~541.7\n",
    "print(f'Training RMSE: {calculate_rmse(y_train, lasso_model.predict(X_train))}')\n",
    "# Should be ~639.4\n",
    "print(f'Test RMSE: {calculate_rmse(y_test, lasso_predictions)}')\n",
    "print('')\n",
    "\n",
    "# Which attributes are most predictive of the outcome variable?\n",
    "print(f'Model coefficients:\\n{lasso_model.coef_}')\n",
    "\n",
    "print()\n",
    "# Note we called this 'lamda' in class, but sklearn calls it alpha (should be ~3.196)\n",
    "print(f'The shinkage coefficient hyperparameter chosen by CV: {lasso_model.alpha_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_lasso-public",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lasso_model, lasso_regression_result = alda_regression_lasso(X_train, X_test, y_train)\n",
    "np.testing.assert_equal(lasso_regression_result.shape, (27,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test, lasso_regression_result), 639.448499767289)\n",
    "np.testing.assert_almost_equal(lasso_model.coef_[0], -201.29823887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_lasso-private",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here's some more test cases\n",
    "df_test = pd.read_csv(\"./data/regression-test.csv\")\n",
    "X_test2 = df_test.iloc[:,:-1]\n",
    "y_test2 = df_test.iloc[:,-1]\n",
    "\n",
    "lasso_model, lasso_regression_result = alda_regression_lasso(X, X_test2, y)\n",
    "np.testing.assert_equal(lasso_regression_result.shape, (66,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test2, lasso_regression_result), 978.5702064182492)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-59f0827753c683dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the results, compare the two regression models, including the training and testing RMSE, and the coefficients. Use the output of these functions to answer the following questions below:\n",
    "\n",
    "1. The dataset contains 19 attributes. Are all 19 attributes useful for predicting the dependent variable? Why or why not? Use your results to justify the answer.\n",
    "2. If not all attributes are predictive, use your Lasso model to perform feature selection. Which attributes should be kept? Use a correlation and/or scatter plot to justify your answer for at least one attribute (in a new cell below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "comparison",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
