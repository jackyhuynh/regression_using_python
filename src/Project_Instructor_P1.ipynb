{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Phase 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we're an up and coming YouTuber (circa 2011-2014), and our goal is to get as popular as fast as possible. To do this, we ask: what types of videos trend and do the best on YouTube?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./project_data/USVideos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to connect our data from our .json file an meld it into our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./project_data/US_category_id.json\") as f:\n",
    "    categories = json.load(f)\n",
    "\n",
    "cat_map = {}\n",
    "for index,cat in enumerate(categories[\"items\"]):\n",
    "    cat_map[int(cat[\"id\"])]=cat[\"snippet\"][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category_id\"].map(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it's always good to get a 5 number summary of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the numbers for `catagory_id` mean nothing since it's a catagorical attribute.\n",
    "\n",
    "Let's look at it for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countplot = sns.countplot(x=df[\"category\"])\n",
    "countplot.set_xticklabels(countplot.get_xticklabels(),rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what do we mean by \"do best\"? We have four possible numeric items that could signal quality, `views`,`likes`,`dislikes`, and `comment_count`. Do we want to optimize for all of them, or just one?\n",
    "\n",
    "Let's dig into these variables a bit and figure out what to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a subset of the dataframe\n",
    "numbers = df[[\"views\",\"likes\",\"dislikes\",\"comment_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We sample a small amount because trying to plot all 40000 rows would be way too slow.\n",
    "small_sample = numbers.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(small_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, looking at our data, it seems like a lot of it is clustered before growing exponentially. That means just running a simple linear correlation would be unwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the image is too small, so let's dig a bit more into one variable. \n",
    "Let's take `views` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"views\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, not much more info. What if we plot it on a log scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"views\"],log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! That looks *a lot* like a normal distribution. In fact, this is what we call a [log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution). While this isn't something we'll go in depth, know that normally distributed data plays very nice with many statistical methods: so it's always a good sign.\n",
    "\n",
    "Using this, let's do a pair plot again, except with all of our data log transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing a log transform, we'll run into problems with taking the log of zero values (because $log(0)=-infinity$). \n",
    "\n",
    "One of the most common workarounds for this is to just add 1 to each variable, then take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_numbers = np.log(numbers+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(log_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's looking pretty correlated to me. (Aside from the row of points along each axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see if there's any redundant, highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_numbers.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `(likes, views)` and `(comment count, likes)` are highly correlated. So if we optimize views, likes will probably follow.\n",
    "\n",
    "**Thus, our goal is to try and predict how many views a video will get based off of the title, description, and tags.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Dates and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for our model, we're not going to use the publish or trending dates. However, it's useful to see how to deal with dates and time when processing data.\n",
    "\n",
    "Another interesting question. When do videos get popular compared to their publish date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = df[[\"trending_date\",\"publish_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These dates are currently in string format. If we want to do more operations on them, we should transform them into a more rich datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_times = pd.to_datetime(times[\"trending_date\"],format=\"%y.%d.%m\")\n",
    "trending_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, this doesn't look that much different, but now we can do a bunch more interesting conversions. For example, let's get the time in seconds:\n",
    "# Converting dates into seconds make them easier to plot\n",
    "trending_times.values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to massage the publish time a bit more. Since we don't care about hours and seconds, we can just lop everything past the `T` seperator off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_times = times[\"publish_time\"].str.slice(0,-14)\n",
    "publish_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_times = pd.to_datetime(publish_times,format=\"%Y.%m.%d\")\n",
    "publish_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_times = pd.DataFrame(data={\"publish_times\":publish_times,\"trending_times\":trending_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_times[\"difference\"] = new_times[\"trending_times\"]-new_times[\"publish_times\"]\n",
    "new_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a 5 number summary of the difference\n",
    "new_times.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is a list of tags: we have to be a bit more clever then just doing bag of words on the whole thing. Since for example, the tag \"nicholas cage\" is different from the tags \"nicholas\" and \"cage\".\n",
    "\n",
    "We use some regex so that our processor captures all of the phrases seperated by a pipe as one word. In addition to this, we strip out all the extra quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tags\"].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r\"([^|]+)\")\n",
    "vectorizer.fit_transform([df[\"tags\"].iloc[10].replace(\"\\\"\",\"\")])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vectorize the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vectorizer = CountVectorizer(token_pattern=r\"([^|]+)\")\n",
    "tag_vectors = tag_vectorizer.fit_transform(df[\"tags\"].str.replace(\"\\\"\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do our simple vectorization that we've done before for the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_vectorizer = CountVectorizer()\n",
    "description_vectors = description_vectorizer.fit_transform(df[\"description\"].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectorizer = CountVectorizer()\n",
    "title_vectors = title_vectorizer.fit_transform(df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Have So Far\n",
    "Let's take a moment and summarize we have so far.\n",
    "\n",
    "We want to predict the *number of views* a video will get, based of it's *title*,*category*, *description*, and *tags* (Since those are the variables we can control when making our video).\n",
    "\n",
    "We then vectorized our title, description, and tags so that we can use them in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = df[[\"title\",\"category\",\"description\",\"tags\",\"views\"]]\n",
    "variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
